{"version":3,"sources":["index.js"],"names":["App","_useState","useState","_useState2","Object","_tmp_deploys_0ot36_ckzehnu210e8f0us8h25d5n8q_source_node_modules_babel_runtime_helpers_esm_slicedToArray__WEBPACK_IMPORTED_MODULE_2__","score","setScore","_useState3","_useState4","isFaceDetected","setIsFaceDetected","video","useRef","useEffect","_ref","_tmp_deploys_0ot36_ckzehnu210e8f0us8h25d5n8q_source_node_modules_babel_runtime_helpers_esm_asyncToGenerator__WEBPACK_IMPORTED_MODULE_1__","_tmp_deploys_0ot36_ckzehnu210e8f0us8h25d5n8q_source_node_modules_babel_runtime_regenerator__WEBPACK_IMPORTED_MODULE_0___default","a","mark","_callee","mediaStream","wrap","_context","prev","next","faceApi","tinyFaceDetector","load","navigator","mediaDevices","getUserMedia","facingMode","sent","current","srcObject","t0","console","log","name","message","stack","stop","apply","this","arguments","run","onPlay","_ref2","_callee2","options","result","_context2","paused","ended","params","setTimeout","abrupt","scoreThreshold","_score","react__WEBPACK_IMPORTED_MODULE_3___default","createElement","className","style","width","height","position","ref","autoPlay","muted","left","right","bottom","top","rootElement","document","getElementById","ReactDOM","render"],"mappings":"sNAMMA,UAAM,WAAM,IAAAC,EACUC,qBADVC,EAAAC,OAAAC,EAAA,EAAAD,CAAAH,EAAA,GACTK,EADSH,EAAA,GACFI,EADEJ,EAAA,GAAAK,EAE4BN,oBAAS,GAFrCO,EAAAL,OAAAC,EAAA,EAAAD,CAAAI,EAAA,GAETE,EAFSD,EAAA,GAEOE,EAFPF,EAAA,GAGVG,EAAQC,mBAEdC,oBAAU,YACC,eAAAC,EAAAX,OAAAY,EAAA,EAAAZ,CAAAa,EAAAC,EAAAC,KAAG,SAAAC,IAAA,IAAAC,EAAA,OAAAJ,EAAAC,EAAAI,KAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAE,MAAA,cAAAF,EAAAC,KAAA,EAAAD,EAAAE,KAAA,EAEFC,IAAaC,iBAAiBC,KAAK,YAFjC,cAAAL,EAAAE,KAAA,EAGkBI,UAAUC,aAAaC,aAAa,CAC5DnB,MAAO,CAAEoB,WAAY,UAJf,OAGFX,EAHEE,EAAAU,KAORrB,EAAMsB,QAAQC,UAAYd,EAPlBE,EAAAE,KAAA,gBAAAF,EAAAC,KAAA,EAAAD,EAAAa,GAAAb,EAAA,SASRc,QAAQC,IAAIf,EAAAa,GAAEG,KAAMhB,EAAAa,GAAEI,QAASjB,EAAAa,GAAEK,OATzB,yBAAAlB,EAAAmB,SAAAtB,EAAA,iBAAH,yBAAAL,EAAA4B,MAAAC,KAAAC,aAAA,EAYTC,IAEC,IAEH,IAAMC,EAAM,eAAAC,EAAA5C,OAAAY,EAAA,EAAAZ,CAAAa,EAAAC,EAAAC,KAAG,SAAA8B,IAAA,IAAAC,EAAAC,EAAA,OAAAlC,EAAAC,EAAAI,KAAA,SAAA8B,GAAA,cAAAA,EAAA5B,KAAA4B,EAAA3B,MAAA,UACbY,QAAQC,IAAI1B,EAAMsB,WAEftB,EAAMsB,SAAWtB,EAAMsB,QAAQmB,QAC/BzC,EAAMsB,SAAWtB,EAAMsB,QAAQoB,QAC/B5B,IAAaC,iBAAiB4B,OALpB,CAAAH,EAAA3B,KAAA,eAOX+B,WAAW,kBAAMT,MAPNK,EAAAK,OAAA,wBAWPP,EAAU,IAAIxB,IAAgC,CAClDgC,eAAgB,KAZLN,EAAA3B,KAAA,EAeQC,IAAyBd,EAAMsB,QAASgB,GAfhD,QAePC,EAfOC,EAAAnB,OAkBXI,QAAQC,IAAIa,GACZ5C,EAAS4C,EAAOQ,QAChBhD,GAAkB,KAElB0B,QAAQC,IAAI,WACZ3B,GAAkB,IAGpB6C,WAAW,kBAAMT,KAAU,KA1Bd,yBAAAK,EAAAV,SAAAO,MAAH,yBAAAD,EAAAL,MAAAC,KAAAC,YAAA,GA6BZ,OACEe,EAAA1C,EAAA2C,cAAA,OAAKC,UAAU,OACbF,EAAA1C,EAAA2C,cAAA,+BACCvD,GAASI,GAAkBkD,EAAA1C,EAAA2C,cAAA,qBAAavD,EAAb,MAC1BI,GAAkBkD,EAAA1C,EAAA2C,cAAA,8BACpBD,EAAA1C,EAAA2C,cAAA,OAAKE,MAAO,CAAEC,MAAO,OAAQC,OAAQ,QAASC,SAAU,aACtDN,EAAA1C,EAAA2C,cAAA,SACEM,IAAKvD,EACLwD,UAAQ,EACRC,OAAK,EACLtB,OAAQA,EACRgB,MAAO,CACLG,SAAU,WACVF,MAAO,OACPC,OAAQ,QACRK,KAAM,EACNC,MAAO,EACPC,OAAQ,EACRC,IAAK,SAQXC,EAAcC,SAASC,eAAe,QAC5CC,IAASC,OAAOlB,EAAA1C,EAAA2C,cAAC7D,EAAD,MAAS0E","file":"static/js/main.55d13de4.chunk.js","sourcesContent":["import React, { useEffect, useRef, useState } from \"react\";\nimport ReactDOM from \"react-dom\";\nimport * as faceApi from \"face-api.js\";\n\nimport \"./styles.css\";\n\nconst App = () => {\n  const [score, setScore] = useState();\n  const [isFaceDetected, setIsFaceDetected] = useState(false);\n  const video = useRef();\n\n  useEffect(() => {\n    const run = async () => {\n      try {\n        await faceApi.nets.tinyFaceDetector.load(\"/models/\");\n        const mediaStream = await navigator.mediaDevices.getUserMedia({\n          video: { facingMode: \"user\" }\n        });\n\n        video.current.srcObject = mediaStream;\n      } catch (e) {\n        console.log(e.name, e.message, e.stack);\n      }\n    };\n    run();\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n  }, []);\n\n  const onPlay = async () => {\n    console.log(video.current);\n    if (\n      (video.current && video.current.paused) ||\n      (video.current && video.current.ended) ||\n      !faceApi.nets.tinyFaceDetector.params\n    ) {\n      setTimeout(() => onPlay());\n      return;\n    }\n\n    const options = new faceApi.TinyFaceDetectorOptions({\n      scoreThreshold: 0.5\n    });\n\n    const result = await faceApi.detectSingleFace(video.current, options);\n\n    if (result) {\n      console.log(result);\n      setScore(result._score);\n      setIsFaceDetected(true);\n    } else {\n      console.log(\"no face\");\n      setIsFaceDetected(false);\n    }\n\n    setTimeout(() => onPlay(), 1000);\n  };\n\n  return (\n    <div className=\"App\">\n      <h1>Face Recognition </h1>\n      {score && isFaceDetected && <h1>Score - {score} </h1>}\n      {!isFaceDetected && <h1> No face in view</h1>}\n      <div style={{ width: \"100%\", height: \"100vh\", position: \"relative\" }}>\n        <video\n          ref={video}\n          autoPlay\n          muted\n          onPlay={onPlay}\n          style={{\n            position: \"absolute\",\n            width: \"100%\",\n            height: \"100vh\",\n            left: 0,\n            right: 0,\n            bottom: 0,\n            top: 0\n          }}\n        />\n      </div>\n    </div>\n  );\n};\n\nconst rootElement = document.getElementById(\"root\");\nReactDOM.render(<App />, rootElement);\n"],"sourceRoot":""}